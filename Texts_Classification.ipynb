{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas in c:\\anaconda\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in c:\\anaconda\\lib\\site-packages (from pandas) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in c:\\anaconda\\lib\\site-packages (from pandas) (2018.5)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in c:\\anaconda\\lib\\site-packages (from pandas) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/6c/6ddb21e203ff95d7080aeee2105b4f6610a02483e00d4ac950f3630969c9/scikit_learn-0.20.2-cp37-cp37m-win_amd64.whl (4.8MB)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.15.4)\n",
      "Installing collected packages: scikit-learn\n",
      "  Found existing installation: scikit-learn 0.20.1\n",
      "    Uninstalling scikit-learn-0.20.1:\n",
      "      Successfully uninstalled scikit-learn-0.20.1\n",
      "Successfully installed scikit-learn-0.20.2\n"
     ]
    }
   ],
   "source": [
    "#update libs\n",
    "!pip install --upgrade pandas\n",
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import common libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.3)\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import special libs\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer,OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer,QuantileTransformer\n",
    "from sklearn.preprocessing import label_binarize,MultiLabelBinarizer\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split \n",
    "from sklearn.model_selection import KFold,RandomizedSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score, brier_score_loss, roc_curve, auc\n",
    "from sklearn.metrics import f1_score, make_scorer, roc_auc_score, precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD,IncrementalPCA\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer # one more stemmer? or lemmatisation\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "seed = 321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет с классифицируемыми текстами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, задача данной работы:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA.\n",
    "\n",
    "Посмотрим на данные, для этого:\n",
    "- скачаем датасет целиком\n",
    "- посмотрим на категории в данных\n",
    "- распределение документов по категориям\n",
    "- посмотрим на примеры данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# здесь shuffle = true, т.к. мы собираемся использовать SGDClassifier; Naive Bayes - они базируются на принципе iid данных \n",
    "#и чтобы не получить смещенную оценку\n",
    "newsgroups_train = fetch_20newsgroups(subset='all', random_state=seed, shuffle=True)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(list(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846 documents\n",
      "20 categories\n"
     ]
    }
   ],
   "source": [
    "print(\"%d documents\" % len(newsgroups_train.data))\n",
    "print(\"%d categories\" % len(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на образец данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: Jim_Johnson@abcd.houghton.mi.us (Jim Johnson)\\nSubject: Run box w/o cover ??\\nOrganization: Amiga BitSwap Central Dispatch\\nLines: 25\\n\\n\\nB(>i am interested in getting the pulse of this group regarding\\nB(>extended operation of my G2K 486-33V with the cover removed\\nB(>from the enclosure.  there are a # of reasons i am considering\\nB(>this, including quick access to jumpers during complex i/o card\\nB(>setups.\\n\\nB(>my concern is that without a complete enclosure to direct the\\nB(>cooling flow of air from the fan, \"hot spots\" may develop on my\\nB(>motherboard or elsewhere.\\n\\nIf you have an adequate supply of air moving over the system (most\\noffices or homes have positive ventilation) you can generally run a\\nsystem without the cover for extended periods without a problem. (I\\'m\\ntalking about completely removing the cover - not just leaving the slots\\nuncovered.) HOWEVER, the biggest reason you have a cover to begin with\\nis RF sheilding. Operating a system without the full cover may create\\nproblems with other equipment such as your neighbor\\'s TV or Ham radio\\nstation - very much a no-no in the eyes of the law.\\n\\n\\n * SLMR 2.1a * Remember - They\\'re only tools, not a way of life!\\n\\n\\n-- Via DlgQWK v0.71a\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing.\n",
    "\n",
    "Предобработаем данные, для этого:\n",
    "- отсечем стоп слова (уберем символы и комбинации, которые не составляют смысловой нагрузки).\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
